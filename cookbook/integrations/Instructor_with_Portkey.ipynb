{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Get structured outputs from 100+ LLMs"
      ],
      "metadata": {
        "id": "QUvn05wUXBbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[**Instructor**](https://github.com/jxnl/instructor) is a Python library for getting structured outputs from LLMs. Built on top of Pydantic, it provides a simple, transparent, and user-friendly API to manage validation, retries, and streaming responses.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Portkey** is an open source [**AI Gateway**](https://github.com/Portkey-AI/gateway) that helps you manage access to 250+ LLMs through a unified API while providing visibility into\n",
        "\n",
        "✅ cost  \n",
        "✅ performance  \n",
        "✅ accuracy metrics\n",
        "\n",
        "This notebook demonstrates how you can get structured outputs from 100s of LLMs using Portkey's AI Gateway."
      ],
      "metadata": {
        "id": "YhM8C8VDXG2Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQLdtnFhWbIE"
      },
      "outputs": [],
      "source": [
        "!pip install -qU instructor portkey-ai openai jsonref"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structured Outputs for OpenAI models"
      ],
      "metadata": {
        "id": "80K8rNtgdvyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "from pydantic import BaseModel\n",
        "from portkey_ai import Portkey\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n",
        "\n",
        "portkey = OpenAI(\n",
        "    base_url=PORTKEY_GATEWAY_URL,\n",
        "    api_key = \"X\",\n",
        "    default_headers=createHeaders(\n",
        "        virtual_key= \"gpt3-8070a6\",\n",
        "        api_key=userdata.get('PORTKEY_API_KEY')\n",
        "\n",
        "    )\n",
        ")\n",
        "\n",
        "class User(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "\n",
        "client = instructor.from_openai(portkey)\n",
        "\n",
        "user_info = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    max_tokens=1024,\n",
        "    response_model=User,\n",
        "    messages=[{\"role\": \"user\", \"content\": \"John Doe is 30 years old.\"}],\n",
        ")\n",
        "\n",
        "print(user_info.name)\n",
        "print(user_info.age)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxjMXaS1cgiY",
        "outputId": "1ebaea29-97cb-4a89-c728-815c52607410"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John Doe\n",
            "30\n"
          ]
        }
      ]
    }
  ]
}