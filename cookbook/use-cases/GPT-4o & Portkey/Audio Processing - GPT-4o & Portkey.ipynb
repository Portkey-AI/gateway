{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1j8MjMt3vbXbeANrEWkkokxRp0rp761eJ?usp=sharing)"],"metadata":{"id":"-CFeL-_-Hbzm"}},{"cell_type":"markdown","source":["<h1 align=\"center\">\n","  <a href=\"https://portkey.ai\">\n","    <img width=\"300\" src=\"https://analyticsindiamag.com/wp-content/uploads/2023/08/Logo-on-white-background.png\" alt=\"portkey\">\n","  </a>\n","</h1>"],"metadata":{"id":"vAYTgTTYHycQ"}},{"cell_type":"markdown","source":["# Audio Processing with GPT-4o\n","\n","\n","\n","*   Transcription\n","*   Summarizing\n","\n"],"metadata":{"id":"W191y633oOeF"}},{"cell_type":"markdown","source":["[Portkey](https://app.portkey.ai/) is the Control Panel for AI apps. With it's popular AI Gateway and Observability Suite, hundreds of teams ship reliable, cost-efficient, and fast apps.\n","\n","With Portkey, you can\n","\n"," - Connect to 150+ models through a unified API,\n"," - View 40+ metrics & logs for all requests,\n"," - Enable semantic cache to reduce latency & costs,\n"," - Implement automatic retries & fallbacks for failed requests,\n","\n"],"metadata":{"id":"tcvgdRJPoOcH"}},{"cell_type":"markdown","source":["You will need Portkey and OpenAIAI API keys to run this notebook.\n","\n","- Sign up for Portkey and generate your API key [here](https://app.portkey.ai/).\n","- Get your OpenAI API key [here](https://console.OpenAI.com/keys)"],"metadata":{"id":"awaa1NR2oTaV"}},{"cell_type":"markdown","source":["# Dependencies"],"metadata":{"id":"0abbh1OgoWwL"}},{"cell_type":"code","source":["!pip install -qU portkey-ai openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D-UU8GwCoS4_","executionInfo":{"status":"ok","timestamp":1715766324772,"user_tz":-330,"elapsed":21744,"user":{"displayName":"Vedant Deshmukh","userId":"12163571168789430680"}},"outputId":"edaf6318-4ef8-4593-988a-940f3db4634d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m976.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n","from google.colab import userdata"],"metadata":{"id":"ILKAIDtzoS2g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Using Portkey with OpenAI Client"],"metadata":{"id":"PLyhmnU5ojct"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOfZrL-en-ku"},"outputs":[],"source":["portkey = OpenAI(\n","    api_key= userdata.get('OPENAI_API_KEY'), ## replace it your OpenAI API key\n","    base_url=PORTKEY_GATEWAY_URL,\n","    default_headers=createHeaders(\n","        provider=\"openai\",\n","        api_key= userdata.get('PORTKEY_API_KEY'), ## replace it your Portkey API key\n","    )\n",")"]},{"cell_type":"markdown","source":["Audio sample [link](https://audio-samples.github.io/samples/mp3/blizzard_primed/sample-0.mp3)"],"metadata":{"id":"S84DbjcFqThr"}},{"cell_type":"markdown","source":["## Transcription"],"metadata":{"id":"fEplCllgqJW1"}},{"cell_type":"code","source":["# Transcribe the audio\n","transcription = portkey.audio.transcriptions.create(\n","    model=\"whisper-1\",\n","    file=open('/content/sample-0.mp3', \"rb\"),\n",")\n","\n","\n","response = portkey.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[\n","    {\"role\": \"system\", \"content\":\"\"\"You are a professional transcriber.\"\"\"},\n","    {\"role\": \"user\", \"content\": [\n","        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"}\n","        ],\n","    }\n","    ],\n","    temperature=0,\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06tCRvzhp73T","executionInfo":{"status":"ok","timestamp":1715766579559,"user_tz":-330,"elapsed":3404,"user":{"displayName":"Vedant Deshmukh","userId":"12163571168789430680"}},"outputId":"a1f0c04a-f3a6-4e17-ae48-dd1154f9921f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["It seems like there might be some errors in the transcription. Based on the context, it could be:\n","\n","\"He doesn't belong to you, and I don't see how you have anything to do with what is his power yet. He's heaped us all in that from the stage to you. Be fine.\"\n","\n","However, without the audio, it's difficult to be certain. If you can provide the audio, I can give a more accurate transcription.\n"]}]},{"cell_type":"markdown","source":["## Summarizing"],"metadata":{"id":"fEh85SnwqL1r"}},{"cell_type":"code","source":["# Transcribe the audio\n","transcription = portkey.audio.transcriptions.create(\n","    model=\"whisper-1\",\n","    file=open('/content/sample-0.mp3', \"rb\"),\n",")\n","\n","\n","response = portkey.chat.completions.create(\n","    model=\"gpt-4o\",\n","    messages=[\n","    {\"role\": \"system\", \"content\":\"\"\"You are generating a transcript summary. Create a summary of the provided transcription. Respond in Markdown.\"\"\"},\n","    {\"role\": \"user\", \"content\": [\n","        {\"type\": \"text\", \"text\": f\"The audio transcription is: {transcription.text}\"}\n","        ],\n","    }\n","    ],\n","    temperature=0,\n",")\n","print(response.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ywgEptvolve","executionInfo":{"status":"ok","timestamp":1715766532959,"user_tz":-330,"elapsed":3497,"user":{"displayName":"Vedant Deshmukh","userId":"12163571168789430680"}},"outputId":"d4104de4-7979-41ab-e90d-d451f9b0cd32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["### Summary\n","\n","The speaker asserts that \"he\" does not belong to the listener and questions the listener's involvement in \"his power.\" The speaker mentions that \"he\" has included everyone, from the stage to the listener, and reassures that everything will be fine.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OnjJhYMzosW8"},"execution_count":null,"outputs":[]}]}