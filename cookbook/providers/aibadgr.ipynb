{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Portkey + AI Badgr\n",
        "\n",
        "[Portkey](https://app.portkey.ai/) is the Control Panel for AI apps. With its popular AI Gateway and Observability Suite, hundreds of teams ship reliable, cost-efficient, and fast apps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use Budget-Friendly AI Badgr API with OpenAI Compatibility using Portkey!\n",
        "\n",
        "AI Badgr is a budget/utility OpenAI-compatible provider that offers tier-based model access:\n",
        "- **basic**: Budget-tier models for simple tasks\n",
        "- **normal**: Standard-tier models for general use\n",
        "- **premium**: High-quality models for complex tasks\n",
        "\n",
        "Since Portkey is fully compatible with the OpenAI signature, you can connect to the Portkey AI Gateway through the OpenAI Client.\n",
        "\n",
        "- Set the `base_url` as `PORTKEY_GATEWAY_URL`\n",
        "- Add `default_headers` to consume the headers needed by Portkey using the `createHeaders` helper method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You will need Portkey and AI Badgr API keys to run this notebook.\n",
        "\n",
        "- Sign up for [Portkey here](https://app.portkey.ai/signup) and generate your API key.\n",
        "- Get your AI Badgr API key from [AI Badgr](https://aibadgr.com)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU portkey-ai openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With OpenAI Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=PORTKEY_GATEWAY_URL,\n",
        "    default_headers=createHeaders(\n",
        "        provider=\"aibadgr\",\n",
        "        api_key=\"YOUR_AIBADGR_API_KEY\"\n",
        "    )\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"What is the meaning of life?\"}],\n",
        "    model=\"premium\"  # Use tier names: basic, normal, or premium\n",
        ")\n",
        "\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With Portkey Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from portkey_ai import Portkey\n",
        "\n",
        "portkey = Portkey(\n",
        "    api_key=\"YOUR_PORTKEY_API_KEY\",\n",
        "    provider=\"aibadgr\",\n",
        "    Authorization=\"YOUR_AIBADGR_API_KEY\"\n",
        ")\n",
        "\n",
        "completion = portkey.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms\"}],\n",
        "    model=\"premium\"\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Streaming Responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stream = portkey.chat.completions.create(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Write a short poem about AI\"}],\n",
        "    model=\"premium\",\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.choices[0].delta.content:\n",
        "        print(chunk.choices[0].delta.content, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Tiers\n",
        "\n",
        "AI Badgr provides tier-based model access optimized for different use cases:\n",
        "\n",
        "- **basic**: Budget-tier models optimized for cost and speed\n",
        "- **normal**: Standard-tier models balancing performance and cost\n",
        "- **premium**: High-quality models for complex reasoning and tasks\n",
        "\n",
        "OpenAI model names are also accepted and automatically mapped to the appropriate tier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observability with Portkey\n",
        "\n",
        "By routing requests through Portkey you can track metrics like:\n",
        "- Token usage and costs\n",
        "- Request latency\n",
        "- Success/error rates\n",
        "\n",
        "View all your analytics at [Portkey Dashboard](https://app.portkey.ai/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}